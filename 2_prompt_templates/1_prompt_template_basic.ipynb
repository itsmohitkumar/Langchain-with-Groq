{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#langchain Documentation:-\n",
    "#[ChatGroq]: https://python.langchain.com/v0.2/docs/integrations/chat/groq/\n",
    "\n",
    "# LangChain Expression Language (LCEL): https://python.langchain.com/v0.1/docs/modules/model_io/chat/quick_start/\n",
    "\n",
    "#LLM Api Documentation:-\n",
    "#[Groq]: https://console.groq.com/docs/quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt Template Docs:\n",
    "#   https://python.langchain.com/v0.2/docs/concepts/#prompt-templateshttps://python.langchain.com/v0.2/docs/concepts/#prompt-templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Zero-shot learning: The model receives a prompt for a task it hasn't been explicitly trained on, without providing any examples.\n",
    "\n",
    "# 2.Few-shot learning: The model is given a few examples of how to perform a task before being asked to generalize to similar tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.2 is available.\n",
      "You should consider upgrading via the '/Users/taurangela/Desktop/Github/Langchain-with-Groq/env/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-groq python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Access the GROQ_API_KEY\n",
    "api_key = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Groq model\n",
    "llm = ChatGroq(\n",
    "    model=\"mixtral-8x7b-32768\" #choose model from the list:https://console.groq.com/docs/models\n",
    ")\n",
    "\n",
    "\n",
    "# Optional configuration\n",
    "# llm = ChatGroq(\n",
    "#     model=\"mixtral-8x7b-32768\",\n",
    "#     temperature=0,\n",
    "#     max_tokens=None,\n",
    "#     timeout=None,\n",
    "#     max_retries=2,\n",
    "#     # other params...\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Prompt from Template-----\n",
      "What do you call a pile of kittens? A meow-ntain! I'll show myself out.\n"
     ]
    }
   ],
   "source": [
    "# PART 1: Create a ChatPromptTemplate using a template string\n",
    "print(\"-----Prompt from Template-----\")\n",
    "\n",
    "template = \"Tell me a joke about {topic}.\"\n",
    "prompt_template = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "prompt = prompt_template.invoke({\"topic\": \"cats\"})\n",
    "result = llm.invoke(prompt)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Zero-Shot Learning Example -----\n",
      "\n",
      "The French translation of the English sentence \"Hello, how are you?\" is \"Bonjour, comment ça va?\" In French, \"Bonjour\" is used to say hello, and \"comment ça va\" is a common way to ask someone how they are doing.\n"
     ]
    }
   ],
   "source": [
    "# PART 1.1: Zero-Shot Learning Example\n",
    "print(\"\\n----- Zero-Shot Learning Example -----\\n\")\n",
    "\n",
    "# Prompt without any prior examples; purely based on model's training\n",
    "zero_shot_prompt = ChatPromptTemplate.from_template(\"Translate the following English sentence to French: '{sentence}'\")\n",
    "prompt = zero_shot_prompt.invoke({\"sentence\": \"Hello, how are you?\"})\n",
    "result = llm.invoke(prompt)\n",
    "print(result.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Prompt with Multiple Placeholders -----\n",
      "\n",
      "Sure, I'd be happy to! Here's a light-hearted story for you:\n",
      "\n",
      "Once upon a time, in the lush bamboo forests of China, there lived a panda named Pambo. Pambo was a bit of an oddball. Unlike other pandas who were content with eating bamboo all day, Pambo had a secret love for... drum rolls please... ice cream!\n",
      "\n",
      "One day, Pambo stumbled upon a forgotten ice cream truck at the edge of the forest. His eyes widened in delight as he saw rows and rows of his favorite flavor - vanilla! With his nimble paws, he managed to open the truck and enjoyed a feast of ice cream.\n",
      "\n",
      "After his delightful meal, Pambo tried to push the ice cream truck back into the forest. But try as he might, the truck was just too heavy. Suddenly, he had a brilliant idea! He started to stack bamboo sticks under the truck, creating a makeshift ramp. With a final push, the truck rolled onto the ramp and into the forest with a soft \"bump\".\n",
      "\n",
      "From that day forward, the forest was filled with the sound of jingling bells as Pambo's ice cream truck became a regular sight, much to the surprise and delight of the other forest creatures. And so, Pambo became the happiest, and certainly the coolest, panda in the forest!\n"
     ]
    }
   ],
   "source": [
    "# PART 2: Prompt with Multiple Placeholders\n",
    "print(\"\\n----- Prompt with Multiple Placeholders -----\\n\")\n",
    "\n",
    "template_multiple = \"\"\"You are a helpful assistant.\n",
    "Human: Tell me a {adjective} short story about a {animal}.\n",
    "Assistant:\"\"\"\n",
    "\n",
    "prompt_multiple = ChatPromptTemplate.from_template(template_multiple)\n",
    "prompt = prompt_multiple.invoke({\"adjective\": \"funny\", \"animal\": \"panda\"})\n",
    "\n",
    "result = llm.invoke(prompt)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Prompt with System and Human Messages (Tuple) -----\n",
      "\n",
      "Sure, I'd be happy to share some lawyer jokes with you! Here they are:\n",
      "\n",
      "1. Why did the lawyer bring a ladder to court?\n",
      "In case he needed to raise the bar!\n",
      "2. What's the difference between a lawyer and a herd of buffalo?\n",
      "The lawyer charges more.\n",
      "3. How does an attorney sleep?\n",
      "First, they lie on one side. Then they lie on the other.\n",
      "\n",
      "I hope these brought a smile to your face! Just remember, they're all in good fun and not meant to offend or stereotype all lawyers.\n"
     ]
    }
   ],
   "source": [
    "# PART 3: Prompt with System and Human Messages (Using Tuples)\n",
    "print(\"\\n----- Prompt with System and Human Messages (Tuple) -----\\n\")\n",
    "\n",
    "messages = [\n",
    "    (\"system\", \"You are a comedian who tells jokes about {topic}.\"),\n",
    "    (\"human\", \"Tell me {joke_count} jokes.\"),\n",
    "]\n",
    "\n",
    "'''\n",
    "# This does NOT work:\n",
    "messages = [\n",
    "    (\"system\", \"You are a comedian who tells jokes about {topic}.\"),\n",
    "    HumanMessage(content=\"Tell me {joke_count} jokes.\"),\n",
    "]\n",
    "'''\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "prompt = prompt_template.invoke({\"topic\": \"lawyers\", \"joke_count\": 3})\n",
    "result = llm.invoke(prompt)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Using Conditional Logic in Prompts -----\n",
      "\n",
      "However, I would recommend doing some research first. Consider factors like the car's model, year, mileage, and maintenance history. You should also compare prices to ensure you're getting a good deal. If you're unsure, you might want to consult with a mechanic or someone knowledgeable about cars. Lastly, make sure it fits into your budget and long-term financial goals.\n"
     ]
    }
   ],
   "source": [
    "# PART 4: Using Conditional Logic in Prompts\n",
    "print(\"\\n----- Using Conditional Logic in Prompts -----\\n\")\n",
    "\n",
    "template_conditional = \"\"\"You are a helpful assistant.\n",
    "Human: Should I {action} the {object}? \n",
    "Assistant: {conditional_response}\"\"\"\n",
    "\n",
    "prompt_conditional = ChatPromptTemplate.from_template(template_conditional)\n",
    "\n",
    "# Example with action \"buy\" and object \"car\"\n",
    "prompt = prompt_conditional.invoke({\n",
    "    \"action\": \"buy\",\n",
    "    \"object\": \"car\",\n",
    "    \"conditional_response\": \"If you need a car and can afford it, yes, you should buy it.\"\n",
    "})\n",
    "\n",
    "result = llm.invoke(prompt)\n",
    "print(result.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Few-Shot Learning Example -----\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid input type <class 'langchain_core.prompts.chat.ChatPromptTemplate'>. Must be a PromptValue, str, or list of BaseMessages.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m few_shot_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(few_shot_examples) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTranslate the following English sentence to French: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThank you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m prompt_template_few_shot \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(few_shot_prompt)\n\u001b[0;32m---> 13\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_template_few_shot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[0;32m~/Desktop/Github/Langchain-with-Groq/env/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:277\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    272\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    273\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    275\u001b[0m         ChatGeneration,\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m--> 277\u001b[0m             [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m],\n\u001b[1;32m    278\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    279\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    280\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    281\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    282\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    283\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    284\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    285\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    286\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/Desktop/Github/Langchain-with-Groq/env/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:260\u001b[0m, in \u001b[0;36mBaseChatModel._convert_input\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatPromptValue(messages\u001b[38;5;241m=\u001b[39mconvert_to_messages(\u001b[38;5;28minput\u001b[39m))\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 260\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28minput\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    262\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust be a PromptValue, str, or list of BaseMessages.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    263\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid input type <class 'langchain_core.prompts.chat.ChatPromptTemplate'>. Must be a PromptValue, str, or list of BaseMessages."
     ]
    }
   ],
   "source": [
    "# PART 5: Few-Shot Learning Example\n",
    "print(\"\\n----- Few-Shot Learning Example -----\\n\")\n",
    "\n",
    "# Providing a few examples for the model to learn from before asking it to generalize\n",
    "few_shot_examples = [\n",
    "    \"Translate the following English sentence to French: 'Good morning' -> 'Bonjour'\",\n",
    "    \"Translate the following English sentence to French: 'Good night' -> 'Bonne nuit'\"\n",
    "]\n",
    "\n",
    "# Now, providing a new example to translate\n",
    "few_shot_prompt = \"\\n\".join(few_shot_examples) + \"\\nTranslate the following English sentence to French: 'Thank you'\"\n",
    "prompt_template_few_shot = ChatPromptTemplate.from_template(few_shot_prompt)\n",
    "result = llm.invoke(prompt_template_few_shot)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Looping Over Multiple Inputs -----\n",
      "\n",
      "Advice on time management: Sure, I'd be happy to help you with time management! Here are some tips that might be helpful:\n",
      "\n",
      "1. Prioritize tasks: Make a list of all the tasks you need to accomplish and rank them in order of importance. Focus on completing the most important tasks first.\n",
      "2. Set goals: Set specific, measurable, achievable, relevant, and time-bound (SMART) goals for yourself. This will help you stay focused and motivated.\n",
      "3. Use a planner or calendar: Use a planner or calendar to schedule your tasks and appointments. This will help you stay organized and on track.\n",
      "4. Break tasks into smaller steps: If a task seems overwhelming, break it down into smaller, more manageable steps. This will make it easier to start and complete.\n",
      "5. Avoid multitasking: Multitasking can be tempting, but it can also lead to mistakes and decreased productivity. Focus on one task at a time.\n",
      "6. Learn to say no: It's okay to say no to requests that don't align with your goals or values. This will help you protect your time and energy.\n",
      "7. Take breaks: Taking short breaks throughout the day can help you stay focused and refreshed. Try the Pomodoro Technique, where you work for 25 minutes and then take a 5-minute break.\n",
      "8. Delegate tasks: If you have too much on your plate, consider delegating tasks to others. This can free up your time and allow you to focus on the most important tasks.\n",
      "9. Eliminate distractions: Identify and eliminate distractions that prevent you from focusing on your tasks. This might include turning off notifications, closing unnecessary tabs on your computer, or finding a quiet workspace.\n",
      "10. Reflect on your time management: At the end of each day, reflect on how you spent your time. Identify what worked well and what didn't, and make adjustments as needed.\n",
      "\n",
      "Remember, time management is a skill that takes practice. Don't be too hard on yourself if you don't get it right immediately. Keep trying, and you'll get better over time!\n",
      "Advice on healthy eating: Sure, I'd be happy to help! Here are some tips for healthy eating:\n",
      "\n",
      "1. Eat a variety of foods: Try to include different types of fruits, vegetables, whole grains, lean proteins, and healthy fats in your diet to ensure that you are getting a wide range of nutrients.\n",
      "2. Watch portion sizes: Pay attention to serving sizes and try not to eat too much of any one food. It's important to eat enough to feel satisfied, but not stuffed.\n",
      "3. Limit processed foods: Try to eat whole, unprocessed foods as much as possible. Processed foods often contain added sugars, sodium, and unhealthy fats.\n",
      "4. Eat plenty of fruits and vegetables: Fruits and vegetables are low in calories and high in fiber, vitamins, and minerals. Try to include them in every meal.\n",
      "5. Choose lean protein sources: Lean protein sources, such as chicken, fish, and tofu, are lower in saturated fat and calories than fatty meats.\n",
      "6. Eat healthy fats: Healthy fats, such as those found in avocados, nuts, and olive oil, can help to keep you feeling full and satisfied.\n",
      "7. Drink plenty of water: Staying hydrated is important for overall health and can help to curb overeating.\n",
      "8. Pay attention to how you feel: Try to listen to your body and eat when you are hungry and stop when you are full.\n",
      "9. Don't skip meals: Skipping meals can lead to overeating later on. Try to eat regular, balanced meals throughout the day.\n",
      "10. Seek professional guidance: If you are having trouble making healthy food choices or have specific dietary needs, consider seeking the help of a registered dietitian or other healthcare professional.\n",
      "Advice on exercise: Exercise is an important part of maintaining good health and well-being. Here are some tips to help you get started with an exercise routine:\n",
      "\n",
      "1. Consult with your doctor before starting any new exercise program, especially if you have any chronic health conditions or are pregnant.\n",
      "2. Choose an activity that you enjoy. You're more likely to stick with an exercise routine if you look forward to it.\n",
      "3. Start slowly and gradually increase the intensity and duration of your workouts. This will help prevent injury and burnout.\n",
      "4. Aim for at least 30 minutes of moderate-intensity exercise most days of the week. This can include activities such as brisk walking, cycling, swimming, or dancing.\n",
      "5. Incorporate strength training exercises, such as lifting weights or doing bodyweight exercises, at least two days a week to help build muscle and boost metabolism.\n",
      "6. Don't forget to include flexibility and balance exercises, such as yoga or tai chi, to improve mobility and reduce the risk of falls.\n",
      "7. Listen to your body and pay attention to signs of fatigue or injury. Rest when needed and give yourself permission to take days off.\n",
      "8. Make exercise a social activity by exercising with a friend or joining a group class. This can help make exercise more enjoyable and motivating.\n",
      "9. Set specific, measurable, and achievable goals for yourself to help you stay motivated and track your progress.\n",
      "10. Remember that any amount of exercise is better than none. Even short bursts of activity, such as taking the stairs instead of the elevator or doing a few jumping jacks during commercial breaks, can add up over time.\n"
     ]
    }
   ],
   "source": [
    "# PART 6: Looping Over Multiple Inputs\n",
    "print(\"\\n----- Looping Over Multiple Inputs -----\\n\")\n",
    "\n",
    "template_loop = \"Give me advice about {topic}.\"\n",
    "prompt_loop = ChatPromptTemplate.from_template(template_loop)\n",
    "\n",
    "# List of topics\n",
    "topics = [\"time management\", \"healthy eating\", \"exercise\"]\n",
    "\n",
    "for topic in topics:\n",
    "    prompt = prompt_loop.invoke({\"topic\": topic})\n",
    "    result = llm.invoke(prompt)\n",
    "    print(f\"Advice on {topic}: {result.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
